{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d8d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 20:09:30,153 : INFO : collecting all words and their counts\n",
      "2026-01-02 20:09:30,156 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PARTIE 1 : √âTUDE DES CONTEXTES (CONCORDANCE)\n",
      "============================================================\n",
      "\n",
      "üîç CONCORDANCE pour 'HOSPITAL' dans GAZA :\n",
      "Displaying 5 of 213 matches:\n",
      "3 401st brigade combat team rantisi hospital video footage released israel defen\n",
      "tem used hamas terrorist connecting hospital militant based oations video idf sp\n",
      "ed raid israel next school 200 yard hospital hagari show oational tunnel electri\n",
      "r tunnel lead bulletproof door gaza hospital coverage prof medium need skeptical\n",
      "und tunnel leading basement rantisi hospital gaza idf idf spokesman intended sho\n",
      "\n",
      "üîç CONCORDANCE pour 'HOSPITAL' dans UKRAINE :\n",
      "Displaying 5 of 72 matches:\n",
      " 10 district strike okhmatdyt child hospital interrupted surgery forced young ca\n",
      "al outcry russian missile hit child hospital kyiv ukrainian president zelenskyy \n",
      "president zelenskyy vow retaliation hospital ukraine largest medical facility ch\n",
      "ovnir said tuesday missile hit wing hospital building conducted dialysis child k\n",
      " reporter estimating overall damage hospital million danielle bell head team tra\n",
      "\n",
      "üîç CONCORDANCE pour 'TERRORIST' dans GAZA :\n",
      "Displaying 5 of 117 matches:\n",
      " intelligence officer stated hamas terrorist given order bring timed detonator \n",
      "plosive sliding door door idf said terrorist still inside according israeli mil\n",
      "iad arik herman tell night america terrorist attack israel israel defense force\n",
      "ed large cache weapon supply hamas terrorist amid attack israel group announced\n",
      "t grenade grenade ammunition hamas terrorist order prevent attack idf see remov\n",
      "\n",
      "üîç CONCORDANCE pour 'SOLDIER' dans UKRAINE :\n",
      "Displaying 5 of 12 matches:\n",
      "rt ukrainian child abducted russian soldier forced reeducation camp report 2nd \n",
      "31 hear russian bragging child know soldier already registered matter fact libe\n",
      "m used seeing tank military vehicle soldier scared cried said needed u support \n",
      "formation location parent ukrainian soldier walk child passing destroyed car du\n",
      " response alleged war crime russian soldier ukraine could verify officially res\n",
      "\n",
      "============================================================\n",
      "PARTIE 2 : CHAMPS S√âMANTIQUES (WORD2VEC)\n",
      "============================================================\n",
      "\n",
      "üß† Entra√Ænement du mod√®le Word2Vec pour GAZA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 20:09:30,187 : INFO : collected 5547 word types from a corpus of 29953 raw words and 56 sentences\n",
      "2026-01-02 20:09:30,194 : INFO : Creating a fresh vocabulary\n",
      "2026-01-02 20:09:30,213 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1285 unique words (23.17% of original 5547, drops 4262)', 'datetime': '2026-01-02T20:09:30.213310', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'prepare_vocab'}\n",
      "2026-01-02 20:09:30,215 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 23180 word corpus (77.39% of original 29953, drops 6773)', 'datetime': '2026-01-02T20:09:30.215697', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'prepare_vocab'}\n",
      "2026-01-02 20:09:30,284 : INFO : deleting the raw counts dictionary of 5547 items\n",
      "2026-01-02 20:09:30,286 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2026-01-02 20:09:30,297 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 19787.906733209493 word corpus (85.4%% of prior 23180)', 'datetime': '2026-01-02T20:09:30.297221', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'prepare_vocab'}\n",
      "2026-01-02 20:09:30,406 : INFO : estimated required memory for 1285 words and 100 dimensions: 1670500 bytes\n",
      "2026-01-02 20:09:30,410 : INFO : resetting layer weights\n",
      "2026-01-02 20:09:30,419 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2026-01-02T20:09:30.419756', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'build_vocab'}\n",
      "2026-01-02 20:09:30,428 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1285 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2026-01-02T20:09:30.428451', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'train'}\n",
      "2026-01-02 20:09:30,519 : INFO : EPOCH 0: training on 29953 raw words (19734 effective words) took 0.1s, 290398 effective words/s\n",
      "2026-01-02 20:09:30,607 : INFO : EPOCH 1: training on 29953 raw words (19791 effective words) took 0.1s, 276160 effective words/s\n",
      "2026-01-02 20:09:30,733 : INFO : EPOCH 2: training on 29953 raw words (19800 effective words) took 0.1s, 198930 effective words/s\n",
      "2026-01-02 20:09:30,842 : INFO : EPOCH 3: training on 29953 raw words (19785 effective words) took 0.1s, 271606 effective words/s\n",
      "2026-01-02 20:09:31,100 : INFO : EPOCH 4: training on 29953 raw words (19794 effective words) took 0.2s, 83970 effective words/s\n",
      "2026-01-02 20:09:31,102 : INFO : Word2Vec lifecycle event {'msg': 'training on 149765 raw words (98904 effective words) took 0.7s, 147150 effective words/s', 'datetime': '2026-01-02T20:09:31.102858', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'train'}\n",
      "2026-01-02 20:09:31,134 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1285, vector_size=100, alpha=0.025>', 'datetime': '2026-01-02T20:09:31.134114', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'created'}\n",
      "2026-01-02 20:09:31,169 : INFO : collecting all words and their counts\n",
      "2026-01-02 20:09:31,203 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2026-01-02 20:09:31,256 : INFO : collected 4296 word types from a corpus of 17937 raw words and 46 sentences\n",
      "2026-01-02 20:09:31,262 : INFO : Creating a fresh vocabulary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Entra√Ænement du mod√®le Word2Vec pour UKRAINE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 20:09:31,344 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 828 unique words (19.27% of original 4296, drops 3468)', 'datetime': '2026-01-02T20:09:31.344610', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'prepare_vocab'}\n",
      "2026-01-02 20:09:31,347 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 12355 word corpus (68.88% of original 17937, drops 5582)', 'datetime': '2026-01-02T20:09:31.347591', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'prepare_vocab'}\n",
      "2026-01-02 20:09:31,384 : INFO : deleting the raw counts dictionary of 4296 items\n",
      "2026-01-02 20:09:31,395 : INFO : sample=0.001 downsamples 62 most-common words\n",
      "2026-01-02 20:09:31,401 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 10330.000299776208 word corpus (83.6%% of prior 12355)', 'datetime': '2026-01-02T20:09:31.401484', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'prepare_vocab'}\n",
      "2026-01-02 20:09:31,456 : INFO : estimated required memory for 828 words and 100 dimensions: 1076400 bytes\n",
      "2026-01-02 20:09:31,462 : INFO : resetting layer weights\n",
      "2026-01-02 20:09:31,501 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2026-01-02T20:09:31.500809', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'build_vocab'}\n",
      "2026-01-02 20:09:31,513 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 828 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2026-01-02T20:09:31.513134', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'train'}\n",
      "2026-01-02 20:09:31,576 : INFO : EPOCH 0: training on 17937 raw words (10294 effective words) took 0.0s, 320761 effective words/s\n",
      "2026-01-02 20:09:31,656 : INFO : EPOCH 1: training on 17937 raw words (10333 effective words) took 0.0s, 241241 effective words/s\n",
      "2026-01-02 20:09:31,720 : INFO : EPOCH 2: training on 17937 raw words (10321 effective words) took 0.0s, 249173 effective words/s\n",
      "2026-01-02 20:09:31,831 : INFO : EPOCH 3: training on 17937 raw words (10318 effective words) took 0.0s, 212114 effective words/s\n",
      "2026-01-02 20:09:31,941 : INFO : EPOCH 4: training on 17937 raw words (10332 effective words) took 0.1s, 163224 effective words/s\n",
      "2026-01-02 20:09:31,949 : INFO : Word2Vec lifecycle event {'msg': 'training on 89685 raw words (51598 effective words) took 0.4s, 119243 effective words/s', 'datetime': '2026-01-02T20:09:31.949185', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'train'}\n",
      "2026-01-02 20:09:31,964 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=828, vector_size=100, alpha=0.025>', 'datetime': '2026-01-02T20:09:31.964817', 'gensim': '4.4.0', 'python': '3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä QUEL EST LE SENS DE 'WAR' ? (Top 5 Synonymes/Associations)\n",
      "üëâ GAZA associe 'war' √† :\n",
      "   - israel (sim: 1.00)\n",
      "   - said (sim: 1.00)\n",
      "   - hamas (sim: 1.00)\n",
      "   - gaza (sim: 1.00)\n",
      "   - one (sim: 1.00)\n",
      "üëâ UKRAINE associe 'war' √† :\n",
      "   - said (sim: 1.00)\n",
      "   - ukraine (sim: 1.00)\n",
      "   - russian (sim: 1.00)\n",
      "   - russia (sim: 1.00)\n",
      "   - ukrainian (sim: 1.00)\n",
      "----------------------------------------\n",
      "\n",
      "üìä QUEL EST LE SENS DE 'CIVILIAN' ? (Top 5 Synonymes/Associations)\n",
      "üëâ GAZA associe 'civilian' √† :\n",
      "   - said (sim: 1.00)\n",
      "   - hamas (sim: 1.00)\n",
      "   - say (sim: 1.00)\n",
      "   - hospital (sim: 1.00)\n",
      "   - gaza (sim: 1.00)\n",
      "üëâ UKRAINE associe 'civilian' √† :\n",
      "   - ukraine (sim: 1.00)\n",
      "   - said (sim: 1.00)\n",
      "   - child (sim: 1.00)\n",
      "   - russia (sim: 1.00)\n",
      "   - ukrainian (sim: 1.00)\n",
      "----------------------------------------\n",
      "\n",
      "üìä QUEL EST LE SENS DE 'CHILD' ? (Top 5 Synonymes/Associations)\n",
      "üëâ GAZA associe 'child' √† :\n",
      "   - hamas (sim: 1.00)\n",
      "   - said (sim: 1.00)\n",
      "   - gaza (sim: 1.00)\n",
      "   - civilian (sim: 1.00)\n",
      "   - one (sim: 1.00)\n",
      "üëâ UKRAINE associe 'child' √† :\n",
      "   - ukraine (sim: 1.00)\n",
      "   - said (sim: 1.00)\n",
      "   - russian (sim: 1.00)\n",
      "   - russia (sim: 1.00)\n",
      "   - ukrainian (sim: 1.00)\n",
      "----------------------------------------\n",
      "\n",
      "üìä QUEL EST LE SENS DE 'MILITARY' ? (Top 5 Synonymes/Associations)\n",
      "üëâ GAZA associe 'military' √† :\n",
      "   - israeli (sim: 1.00)\n",
      "   - hamas (sim: 1.00)\n",
      "   - said (sim: 1.00)\n",
      "   - day (sim: 1.00)\n",
      "   - gaza (sim: 1.00)\n",
      "üëâ UKRAINE associe 'military' √† :\n",
      "   - child (sim: 1.00)\n",
      "   - ukraine (sim: 1.00)\n",
      "   - russian (sim: 1.00)\n",
      "   - city (sim: 1.00)\n",
      "   - said (sim: 1.00)\n",
      "----------------------------------------\n",
      "\n",
      "üìä QUEL EST LE SENS DE 'LEADER' ? (Top 5 Synonymes/Associations)\n",
      "üëâ GAZA associe 'leader' √† :\n",
      "   - group (sim: 1.00)\n",
      "   - israel (sim: 1.00)\n",
      "   - one (sim: 1.00)\n",
      "   - day (sim: 1.00)\n",
      "   - including (sim: 1.00)\n",
      "üëâ UKRAINE associe 'leader' √† :\n",
      "   - said (sim: 1.00)\n",
      "   - u (sim: 1.00)\n",
      "   - people (sim: 1.00)\n",
      "   - child (sim: 1.00)\n",
      "   - ukraine (sim: 1.00)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# PROJET NLP HPC : ANALYSE S√âMANTIQUE (CONCORDANCE & EMBEDDINGS)\n",
    "# =================================================================\n",
    "# Objectif : Comparer le sens des mots (Word2Vec) et leur contexte (Concordance)\n",
    "# =================================================================\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "from nltk.text import Text\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# --- 1. CHARGEMENT DES DONN√âES ---\n",
    "def charger_corpus_brut(chemin):\n",
    "    with open(chemin, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    # Pour Word2Vec, on a besoin d'une liste de listes de mots (sentences)\n",
    "    sentences = [art['lexical_view'] for art in data]\n",
    "    return sentences\n",
    "\n",
    "# --- 2. ANALYSE DE CONCORDANCE (Le Microscope) ---\n",
    "def afficher_concordance(tokens, mot_cible, label, lignes=5):\n",
    "    print(f\"\\nüîç CONCORDANCE pour '{mot_cible.upper()}' dans {label} :\")\n",
    "    text_obj = Text(tokens)\n",
    "    # Affiche le mot dans son contexte (fen√™tre de mots autour)\n",
    "    text_obj.concordance(mot_cible, width=80, lines=lignes)\n",
    "\n",
    "# --- 3. ENTRA√éNEMENT WORD2VEC (L'Intelligence S√©mantique) ---\n",
    "def entrainer_modele(sentences, label):\n",
    "    print(f\"\\nüß† Entra√Ænement du mod√®le Word2Vec pour {label}...\")\n",
    "    # Vector_size=100 : chaque mot devient un vecteur de 100 dimensions\n",
    "    # Window=5 : on regarde 5 mots avant et apr√®s pour comprendre le sens\n",
    "    # Min_count=5 : on ignore les mots trop rares\n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "    return model\n",
    "\n",
    "# --- 4. COMPARAISON DES CHAMPS S√âMANTIQUES ---\n",
    "def comparer_voisins(model_gaza, model_ukraine, mot_pivot):\n",
    "    print(f\"\\nüìä QUEL EST LE SENS DE '{mot_pivot.upper()}' ? (Top 5 Synonymes/Associations)\")\n",
    "    \n",
    "    # V√©rification si le mot existe dans le vocabulaire\n",
    "    try:\n",
    "        voisins_g = model_gaza.wv.most_similar(mot_pivot, topn=5)\n",
    "        print(f\"üëâ GAZA associe '{mot_pivot}' √† :\")\n",
    "        for mot, score in voisins_g:\n",
    "            print(f\"   - {mot} (sim: {score:.2f})\")\n",
    "    except KeyError:\n",
    "        print(f\"üëâ GAZA : Le mot '{mot_pivot}' n'est pas assez fr√©quent.\")\n",
    "\n",
    "    try:\n",
    "        voisins_u = model_ukraine.wv.most_similar(mot_pivot, topn=5)\n",
    "        print(f\"üëâ UKRAINE associe '{mot_pivot}' √† :\")\n",
    "        for mot, score in voisins_u:\n",
    "            print(f\"   - {mot} (sim: {score:.2f})\")\n",
    "    except KeyError:\n",
    "        print(f\"üëâ UKRAINE : Le mot '{mot_pivot}' n'est pas assez fr√©quent.\")\n",
    "\n",
    "# --- EX√âCUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Chargement\n",
    "    sentences_gaza = charger_corpus_brut('corpus/corpus_gaza_pretraiter.json')\n",
    "    sentences_ukraine = charger_corpus_brut('corpus/corpus_ukraine_pretraiter.json')\n",
    "    \n",
    "    # Aplatir pour NLTK (Concordance a besoin d'une seule longue liste)\n",
    "    all_tokens_gaza = [w for s in sentences_gaza for w in s]\n",
    "    all_tokens_ukraine = [w for s in sentences_ukraine for w in s]\n",
    "    \n",
    "    # 2. CONCORDANCE (√âtudier les contextes d'utilisation)\n",
    "    # On regarde comment sont utilis√©s les mots \"hospital\" et \"soldier/military\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"PARTIE 1 : √âTUDE DES CONTEXTES (CONCORDANCE)\")\n",
    "    print(\"=\"*60)\n",
    "    afficher_concordance(all_tokens_gaza, 'hospital', 'GAZA')\n",
    "    afficher_concordance(all_tokens_ukraine, 'hospital', 'UKRAINE')\n",
    "    \n",
    "    afficher_concordance(all_tokens_gaza, 'terrorist', 'GAZA')\n",
    "    # Note: Terrorist est rare en Ukraine, on essaie 'soldier'\n",
    "    afficher_concordance(all_tokens_ukraine, 'soldier', 'UKRAINE')\n",
    "\n",
    "    # 3. WORD2VEC (Comparer les champs s√©mantiques)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PARTIE 2 : CHAMPS S√âMANTIQUES (WORD2VEC)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Entra√Ænement des deux cerveaux\n",
    "    w2v_gaza = entrainer_modele(sentences_gaza, 'GAZA')\n",
    "    w2v_ukraine = entrainer_modele(sentences_ukraine, 'UKRAINE')\n",
    "    \n",
    "    # Comparaison des concepts cl√©s\n",
    "    mots_a_tester = ['war', 'civilian', 'child', 'military', 'leader']\n",
    "    \n",
    "    for mot in mots_a_tester:\n",
    "        comparer_voisins(w2v_gaza, w2v_ukraine, mot)\n",
    "        print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
